{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhNHOk6RzDArqJkmHgYwak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5ditto/AP/blob/main/FasterR_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Faster R-CNN** - Projeto de Aprendizagem Profunda"
      ],
      "metadata": {
        "id": "uvyrUfu7kFI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "UC5RFWW-uZGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Escolha do GPU (Tesla T4)"
      ],
      "metadata": {
        "id": "D1Z6xX1rue8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7rVhiTPkgkd",
        "outputId": "6d7d952e-7907-4b29-ae22-ba0acf2e6b7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 17 17:45:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone do repositório que contém o modelo que vamos utilizar"
      ],
      "metadata": {
        "id": "cr9wqpw-ulje"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSFdPf65j_Qv",
        "outputId": "b2718df4-b381-4ba5-8c1f-73b445d76ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastercnn-pytorch-training-pipeline'...\n",
            "remote: Enumerating objects: 1337, done.\u001b[K\n",
            "remote: Counting objects: 100% (433/433), done.\u001b[K\n",
            "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
            "remote: Total 1337 (delta 325), reused 321 (delta 285), pack-reused 904\u001b[K\n",
            "Receiving objects: 100% (1337/1337), 12.82 MiB | 22.52 MiB/s, done.\n",
            "Resolving deltas: 100% (907/907), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sovit-123/fastercnn-pytorch-training-pipeline.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd fastercnn-pytorch-training-pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRRcMGLJkm-F",
        "outputId": "acd5aeec-a86e-448b-e83e-10de489d746f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fastercnn-pytorch-training-pipeline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar requisitos"
      ],
      "metadata": {
        "id": "mqhuMnkAu4o8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BAyAx_eNkwOc",
        "outputId": "a00f711d-cad5-4e62-881a-37ba4418f9c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (7.34.0)\n",
            "Collecting jupyter (from -r requirements.txt (line 4))\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.1.26 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (6.0.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (1.25.2)\n",
            "Collecting protobuf<=3.20.1 (from -r requirements.txt (line 16))\n",
            "  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.66.4)\n",
            "Collecting deep-sort-realtime (from -r requirements.txt (line 19))\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 22))\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (2.15.2)\n",
            "Collecting torchinfo (from -r requirements.txt (line 26))\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (2.0.7)\n",
            "Collecting setuptools==59.5.0 (from -r requirements.txt (line 30))\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics (from -r requirements.txt (line 31))\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vision_transformers (from -r requirements.txt (line 34))\n",
            "  Downloading vision_transformers-0.1.1.0.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.1.0->-r requirements.txt (line 2)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.1.0->-r requirements.txt (line 2)) (4.9.0.80)\n",
            "Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 3))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 4)) (6.5.5)\n",
            "Collecting qtconsole (from jupyter->-r requirements.txt (line 4))\n",
            "  Downloading qtconsole-5.5.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 4)) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 4)) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->-r requirements.txt (line 4)) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 10)) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 10)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 10)) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 10)) (1.6.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 11)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 13)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 13)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 13)) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 13)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 13)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 13)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12.0->-r requirements.txt (line 13))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 17)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 17)) (2024.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 22)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 22))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 22))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 22)) (4.2.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 22)) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 22)) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 22))\n",
            "  Downloading sentry_sdk-2.2.0-py2.py3-none-any.whl (281 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 22))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (3.6)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 23)) (3.0.3)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->-r requirements.txt (line 31))\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 22))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 23)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 23)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 23)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 23)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 3)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 3)) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 22)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 22)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 22)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 22)) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 23)) (2.1.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 4)) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 4)) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->-r requirements.txt (line 4)) (3.0.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 4)) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 4)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 4)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 4)) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->-r requirements.txt (line 4)) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->-r requirements.txt (line 4))\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->-r requirements.txt (line 13)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 22))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 4)) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 4)) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 4)) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 4)) (4.19.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 23)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 23)) (3.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 4)) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 4)) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 4)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 4)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 4)) (0.18.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 4)) (2.22)\n",
            "Building wheels for collected packages: vision_transformers\n",
            "  Building wheel for vision_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vision_transformers: filename=vision_transformers-0.1.1.0-py3-none-any.whl size=48412 sha256=9c2eec896cfe69ef970baa14e6cf0a25e263092937b72fce2e62e06ba4d57031\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/f4/94/0a5c8d2a4fcb6aa4c590906ffd3d52dc8edbe94262ecaa7dae\n",
            "Successfully built vision_transformers\n",
            "Installing collected packages: torchinfo, smmap, setuptools, setproctitle, sentry-sdk, qtpy, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lightning-utilities, gitdb, deep-sort-realtime, nvidia-cusolver-cu12, gitpython, wandb, qtconsole, torchmetrics, vision_transformers, jupyter\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "cvxpy 1.3.4 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.51.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deep-sort-realtime-1.3.2 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 jedi-0.19.1 jupyter-1.0.0 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 protobuf-3.20.1 qtconsole-5.5.2 qtpy-2.4.1 sentry-sdk-2.2.0 setproctitle-1.3.3 setuptools-59.5.0 smmap-5.0.1 torchinfo-1.8.0 torchmetrics-1.4.0.post0 vision_transformers-0.1.1.0 wandb-0.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "google",
                  "pkg_resources",
                  "setuptools"
                ]
              },
              "id": "bdc313c0fef345c09ebfb5188b08104d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD3p0MlioXQq",
        "outputId": "90dfda08-3468-4137-e7b6-9d24457d5c2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fastercnn-pytorch-training-pipeline/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"73iRe6Yh6q25pN4arNF2\")\n",
        "project = rf.workspace(\"roboflow-58fyf\").project(\"rock-paper-scissors-sxsw\")\n",
        "version = project.version(14)\n",
        "dataset = version.download(\"voc\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GeESlRhhn6aw",
        "outputId": "81e233b3-46f9-4430-af06-7159a8303d38"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.29-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.29\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler"
                ]
              },
              "id": "5f9b7d953ab24a449384aee762f9ae6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Rock-Paper-Scissors-SXSW-14 to voc:: 100%|██████████| 236622/236622 [00:09<00:00, 25763.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Rock-Paper-Scissors-SXSW-14 in voc:: 100%|██████████| 14675/14675 [00:02<00:00, 6867.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def organize_files(base_path):\n",
        "    # Definir os nomes das pastas que queremos organizar\n",
        "    folders = ['train', 'test', 'valid']\n",
        "    # Loop através das pastas principais\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(base_path, folder)\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"A pasta {folder_path} não existe.\")\n",
        "            continue\n",
        "\n",
        "        # Criar subpastas para .jpg e .xml se não existirem\n",
        "        jpg_folder = os.path.join(folder_path, 'jpg')\n",
        "        xml_folder = os.path.join(folder_path, 'xml')\n",
        "\n",
        "        os.makedirs(jpg_folder, exist_ok=True)\n",
        "        os.makedirs(xml_folder, exist_ok=True)\n",
        "\n",
        "        # Mover arquivos .jpg e .xml para as subpastas correspondentes\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            if os.path.isfile(file_path):\n",
        "                if file_name.endswith('.jpg'):\n",
        "                    shutil.move(file_path, os.path.join(jpg_folder, file_name))\n",
        "                elif file_name.endswith('.xml'):\n",
        "                    shutil.move(file_path, os.path.join(xml_folder, file_name))\n",
        "\n",
        "        print(f\"Arquivos na pasta {folder} foram organizados.\")\n",
        "\n",
        "# Exemplo de uso:\n",
        "base_path = '/content/fastercnn-pytorch-training-pipeline/data/Rock-Paper-Scissors-SXSW-14'\n",
        "organize_files(base_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ONeL4l4zHd_",
        "outputId": "17e60e3a-6d0d-459a-9a90-88aadc64871b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivos na pasta train foram organizados.\n",
            "Arquivos na pasta test foram organizados.\n",
            "Arquivos na pasta valid foram organizados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "def create_yaml_file():\n",
        "    # Defina o caminho para a pasta data_configs e o nome do arquivo yaml\n",
        "    data_configs_dir = '/content/fastercnn-pytorch-training-pipeline/data_configs'\n",
        "    yaml_file_path = os.path.join(data_configs_dir, 'grupo.yaml')\n",
        "\n",
        "    config_data = \"\"\"\n",
        "TRAIN_DIR_IMAGES: /content/fastercnn-pytorch-training-pipeline/data/Rock-Paper-Scissors-SXSW-14/train/jpg\n",
        "TRAIN_DIR_LABELS: /content/fastercnn-pytorch-training-pipeline/data/Rock-Paper-Scissors-SXSW-14/train/xml\n",
        "VALID_DIR_IMAGES: /content/fastercnn-pytorch-training-pipeline/data/Rock-Paper-Scissors-SXSW-14/valid/jpg\n",
        "VALID_DIR_LABELS: /content/fastercnn-pytorch-training-pipeline/data/Rock-Paper-Scissors-SXSW-14/valid/xml\n",
        "\n",
        "# Class names.\n",
        "CLASSES: [\n",
        "    '__background__',\n",
        "    'Paper',\n",
        "    'Rock',\n",
        "    'Scissors'\n",
        "]\n",
        "\n",
        "# Number of classes (object classes + 1 for background class in Faster RCNN).\n",
        "NC: 4\n",
        "\n",
        "# Whether to save the predictions of the validation set while training.\n",
        "SAVE_VALID_PREDICTION_IMAGES: True\n",
        "\"\"\"\n",
        "    # Certifique-se de que a pasta data_configs exista\n",
        "    os.makedirs(data_configs_dir, exist_ok=True)\n",
        "\n",
        "    # Escreva o conteúdo no arquivo yaml\n",
        "    with open(yaml_file_path, 'w') as yaml_file:\n",
        "        yaml.dump(config_data, yaml_file, default_flow_style=False)\n",
        "\n",
        "    print(f\"Arquivo YAML criado em: {yaml_file_path}\")\n",
        "\n",
        "# Chame a função para criar o arquivo yaml\n",
        "create_yaml_file()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPuchRKU0C46",
        "outputId": "848dc15b-2abb-407e-c808-cae77b4880be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo YAML criado em: /content/fastercnn-pytorch-training-pipeline/data_configs/grupo.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "id": "Yxf0lqCY14NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbSTQ5PB1x-D",
        "outputId": "de161e9f-b1cf-4ce3-8c40-95a56c83b200"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_config.yml    eval.py             __init__.py              onnx_inference_video.py  train.py\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/          \u001b[01;34mexample_test_data\u001b[0m/  LICENSE                  \u001b[01;34mreadme_images\u001b[0m/           \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mdata_configs\u001b[0m/  export.py           \u001b[01;34mmodels\u001b[0m/                  README.md\n",
            "datasets.py    inference.py        \u001b[01;34mnotebook_examples\u001b[0m/       requirements.txt\n",
            "\u001b[01;34mdocs\u001b[0m/          inference_video.py  onnx_inference_image.py  \u001b[01;34mtorch_utils\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data_configs/grupo.yaml --epochs 3 --model fasterrcnn_resnet50_fpn --name teste --batch 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XctciAfM1qSp",
        "outputId": "ed1b5921-92ae-478b-b075-d5960e15c179"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-17 20:25:49.267466: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-17 20:25:49.267516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-17 20:25:49.268871: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-17 20:25:50.349598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not using distributed mode\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://wandb.ai/authorize?signup=true\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/fastercnn-pytorch-training-pipeline/wandb/run-20240517_202756-ffdtxeyx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mteste\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/165grinch/fastercnn-pytorch-training-pipeline\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/165grinch/fastercnn-pytorch-training-pipeline/runs/ffdtxeyx\u001b[0m\n",
            "device cuda\n",
            "Checking Labels and images...\n",
            "100% 6455/6455 [00:00<00:00, 20951.43it/s]\n",
            "Checking Labels and images...\n",
            "100% 576/576 [00:00<00:00, 147582.11it/s]\n",
            "Creating data loaders\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Number of training samples: 6455\n",
            "Number of validation samples: 576\n",
            "\n",
            "Building model from scratch...\n",
            "==================================================================================================================================\n",
            "Layer (type (var_name))                                 Input Shape               Output Shape              Param #\n",
            "==================================================================================================================================\n",
            "FasterRCNN (FasterRCNN)                                 [16, 3, 640, 640]         [100, 4]                  --\n",
            "├─GeneralizedRCNNTransform (transform)                  [16, 3, 640, 640]         [16, 3, 640, 640]         --\n",
            "├─BackboneWithFPN (backbone)                            [16, 3, 640, 640]         [16, 256, 10, 10]         --\n",
            "│    └─IntermediateLayerGetter (body)                   [16, 3, 640, 640]         [16, 2048, 20, 20]        --\n",
            "│    │    └─Conv2d (conv1)                              [16, 3, 640, 640]         [16, 64, 320, 320]        (9,408)\n",
            "│    │    └─FrozenBatchNorm2d (bn1)                     [16, 64, 320, 320]        [16, 64, 320, 320]        --\n",
            "│    │    └─ReLU (relu)                                 [16, 64, 320, 320]        [16, 64, 320, 320]        --\n",
            "│    │    └─MaxPool2d (maxpool)                         [16, 64, 320, 320]        [16, 64, 160, 160]        --\n",
            "│    │    └─Sequential (layer1)                         [16, 64, 160, 160]        [16, 256, 160, 160]       (212,992)\n",
            "│    │    └─Sequential (layer2)                         [16, 256, 160, 160]       [16, 512, 80, 80]         1,212,416\n",
            "│    │    └─Sequential (layer3)                         [16, 512, 80, 80]         [16, 1024, 40, 40]        7,077,888\n",
            "│    │    └─Sequential (layer4)                         [16, 1024, 40, 40]        [16, 2048, 20, 20]        14,942,208\n",
            "│    └─FeaturePyramidNetwork (fpn)                      [16, 256, 160, 160]       [16, 256, 10, 10]         --\n",
            "│    │    └─ModuleList (inner_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─ModuleList (layer_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─ModuleList (inner_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─ModuleList (layer_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─ModuleList (inner_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─ModuleList (layer_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─ModuleList (inner_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─ModuleList (layer_blocks)                   --                        --                        (recursive)\n",
            "│    │    └─LastLevelMaxPool (extra_blocks)             [16, 256, 160, 160]       [16, 256, 160, 160]       --\n",
            "├─RegionProposalNetwork (rpn)                           [16, 3, 640, 640]         [1000, 4]                 --\n",
            "│    └─RPNHead (head)                                   [16, 256, 160, 160]       [16, 3, 160, 160]         --\n",
            "│    │    └─Sequential (conv)                           [16, 256, 160, 160]       [16, 256, 160, 160]       590,080\n",
            "│    │    └─Conv2d (cls_logits)                         [16, 256, 160, 160]       [16, 3, 160, 160]         771\n",
            "│    │    └─Conv2d (bbox_pred)                          [16, 256, 160, 160]       [16, 12, 160, 160]        3,084\n",
            "│    │    └─Sequential (conv)                           [16, 256, 80, 80]         [16, 256, 80, 80]         (recursive)\n",
            "│    │    └─Conv2d (cls_logits)                         [16, 256, 80, 80]         [16, 3, 80, 80]           (recursive)\n",
            "│    │    └─Conv2d (bbox_pred)                          [16, 256, 80, 80]         [16, 12, 80, 80]          (recursive)\n",
            "│    │    └─Sequential (conv)                           [16, 256, 40, 40]         [16, 256, 40, 40]         (recursive)\n",
            "│    │    └─Conv2d (cls_logits)                         [16, 256, 40, 40]         [16, 3, 40, 40]           (recursive)\n",
            "│    │    └─Conv2d (bbox_pred)                          [16, 256, 40, 40]         [16, 12, 40, 40]          (recursive)\n",
            "│    │    └─Sequential (conv)                           [16, 256, 20, 20]         [16, 256, 20, 20]         (recursive)\n",
            "│    │    └─Conv2d (cls_logits)                         [16, 256, 20, 20]         [16, 3, 20, 20]           (recursive)\n",
            "│    │    └─Conv2d (bbox_pred)                          [16, 256, 20, 20]         [16, 12, 20, 20]          (recursive)\n",
            "│    │    └─Sequential (conv)                           [16, 256, 10, 10]         [16, 256, 10, 10]         (recursive)\n",
            "│    │    └─Conv2d (cls_logits)                         [16, 256, 10, 10]         [16, 3, 10, 10]           (recursive)\n",
            "│    │    └─Conv2d (bbox_pred)                          [16, 256, 10, 10]         [16, 12, 10, 10]          (recursive)\n",
            "│    └─AnchorGenerator (anchor_generator)               [16, 3, 640, 640]         [102300, 4]               --\n",
            "├─RoIHeads (roi_heads)                                  [16, 256, 160, 160]       [100, 4]                  --\n",
            "│    └─MultiScaleRoIAlign (box_roi_pool)                [16, 256, 160, 160]       [16000, 256, 7, 7]        --\n",
            "│    └─TwoMLPHead (box_head)                            [16000, 256, 7, 7]        [16000, 1024]             --\n",
            "│    │    └─Linear (fc6)                                [16000, 12544]            [16000, 1024]             12,846,080\n",
            "│    │    └─Linear (fc7)                                [16000, 1024]             [16000, 1024]             1,049,600\n",
            "│    └─FastRCNNPredictor (box_predictor)                [16000, 1024]             [16000, 4]                --\n",
            "│    │    └─Linear (cls_score)                          [16000, 1024]             [16000, 4]                4,100\n",
            "│    │    └─Linear (bbox_pred)                          [16000, 1024]             [16000, 16]               16,400\n",
            "==================================================================================================================================\n",
            "Total params: 41,309,411\n",
            "Trainable params: 41,087,011\n",
            "Non-trainable params: 222,400\n",
            "Total mult-adds (T): 1.45\n",
            "==================================================================================================================================\n",
            "Input size (MB): 78.64\n",
            "Forward/backward pass size (MB): 15288.77\n",
            "Params size (MB): 165.24\n",
            "Estimated Total Size (MB): 15532.65\n",
            "==================================================================================================================================\n",
            "41,309,411 total parameters.\n",
            "41,087,011 training parameters.\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch: [0]  [  0/404]  eta: 0:32:47  lr: 0.000003  loss: 1.7816 (1.7816)  loss_classifier: 1.6626 (1.6626)  loss_box_reg: 0.0899 (0.0899)  loss_objectness: 0.0245 (0.0245)  loss_rpn_box_reg: 0.0046 (0.0046)  time: 4.8707  data: 2.6876  max mem: 7385\n",
            "Epoch: [0]  [100/404]  eta: 0:09:31  lr: 0.000251  loss: 0.2465 (0.5331)  loss_classifier: 0.1235 (0.4147)  loss_box_reg: 0.1053 (0.0896)  loss_objectness: 0.0148 (0.0251)  loss_rpn_box_reg: 0.0030 (0.0036)  time: 1.8728  data: 0.0523  max mem: 7544\n",
            "Epoch: [0]  [200/404]  eta: 0:06:22  lr: 0.000499  loss: 0.2044 (0.3760)  loss_classifier: 0.0917 (0.2591)  loss_box_reg: 0.0971 (0.0947)  loss_objectness: 0.0081 (0.0190)  loss_rpn_box_reg: 0.0024 (0.0032)  time: 1.8674  data: 0.0490  max mem: 7544\n",
            "Epoch: [0]  [300/404]  eta: 0:03:14  lr: 0.000747  loss: 0.1681 (0.3163)  loss_classifier: 0.0712 (0.2013)  loss_box_reg: 0.0872 (0.0965)  loss_objectness: 0.0057 (0.0156)  loss_rpn_box_reg: 0.0018 (0.0029)  time: 1.8959  data: 0.0586  max mem: 7544\n",
            "Epoch: [0]  [400/404]  eta: 0:00:07  lr: 0.000995  loss: 0.1773 (0.2818)  loss_classifier: 0.0776 (0.1701)  loss_box_reg: 0.0958 (0.0958)  loss_objectness: 0.0038 (0.0131)  loss_rpn_box_reg: 0.0019 (0.0028)  time: 1.8491  data: 0.0451  max mem: 7544\n",
            "Epoch: [0]  [403/404]  eta: 0:00:01  lr: 0.001000  loss: 0.1769 (0.2812)  loss_classifier: 0.0707 (0.1695)  loss_box_reg: 0.0930 (0.0959)  loss_objectness: 0.0037 (0.0130)  loss_rpn_box_reg: 0.0021 (0.0028)  time: 1.8060  data: 0.0458  max mem: 7544\n",
            "Epoch: [0] Total time: 0:12:35 (1.8712 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/36]  eta: 0:01:11  model_time: 0.9360 (0.9360)  evaluator_time: 0.0234 (0.0234)  time: 1.9808  data: 0.7013  max mem: 7544\n",
            "Test:  [35/36]  eta: 0:00:00  model_time: 0.8154 (0.8192)  evaluator_time: 0.0175 (0.0249)  time: 0.9236  data: 0.0455  max mem: 7544\n",
            "Test: Total time: 0:00:34 (0.9672 s / it)\n",
            "Averaged stats: model_time: 0.8154 (0.8192)  evaluator_time: 0.0175 (0.0249)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.37s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.373\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "BEST VALIDATION mAP: 0.1637578826654452\n",
            "\n",
            "SAVING BEST MODEL FOR EPOCH: 1\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch: [1]  [  0/404]  eta: 0:19:17  lr: 0.001000  loss: 0.1279 (0.1279)  loss_classifier: 0.0588 (0.0588)  loss_box_reg: 0.0638 (0.0638)  loss_objectness: 0.0034 (0.0034)  loss_rpn_box_reg: 0.0019 (0.0019)  time: 2.8652  data: 0.8663  max mem: 7544\n",
            "Epoch: [1]  [100/404]  eta: 0:09:31  lr: 0.001000  loss: 0.1285 (0.1447)  loss_classifier: 0.0576 (0.0647)  loss_box_reg: 0.0642 (0.0738)  loss_objectness: 0.0029 (0.0041)  loss_rpn_box_reg: 0.0019 (0.0021)  time: 1.8624  data: 0.0562  max mem: 7544\n",
            "Epoch: [1]  [200/404]  eta: 0:06:21  lr: 0.001000  loss: 0.1202 (0.1361)  loss_classifier: 0.0549 (0.0609)  loss_box_reg: 0.0602 (0.0692)  loss_objectness: 0.0019 (0.0040)  loss_rpn_box_reg: 0.0019 (0.0020)  time: 1.8799  data: 0.0548  max mem: 7544\n",
            "Epoch: [1]  [300/404]  eta: 0:03:14  lr: 0.001000  loss: 0.1129 (0.1298)  loss_classifier: 0.0511 (0.0582)  loss_box_reg: 0.0576 (0.0657)  loss_objectness: 0.0025 (0.0039)  loss_rpn_box_reg: 0.0020 (0.0020)  time: 1.8615  data: 0.0494  max mem: 7544\n",
            "Epoch: [1]  [400/404]  eta: 0:00:07  lr: 0.001000  loss: 0.0968 (0.1234)  loss_classifier: 0.0466 (0.0556)  loss_box_reg: 0.0495 (0.0622)  loss_objectness: 0.0016 (0.0038)  loss_rpn_box_reg: 0.0017 (0.0019)  time: 1.8533  data: 0.0473  max mem: 7544\n",
            "Epoch: [1]  [403/404]  eta: 0:00:01  lr: 0.001000  loss: 0.0968 (0.1233)  loss_classifier: 0.0461 (0.0555)  loss_box_reg: 0.0521 (0.0621)  loss_objectness: 0.0012 (0.0037)  loss_rpn_box_reg: 0.0017 (0.0019)  time: 1.8022  data: 0.0442  max mem: 7544\n",
            "Epoch: [1] Total time: 0:12:34 (1.8665 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/36]  eta: 0:01:18  model_time: 0.8994 (0.8994)  evaluator_time: 0.0159 (0.0159)  time: 2.1729  data: 0.9395  max mem: 7544\n",
            "Test:  [35/36]  eta: 0:00:00  model_time: 0.8041 (0.8139)  evaluator_time: 0.0112 (0.0155)  time: 0.8974  data: 0.0411  max mem: 7544\n",
            "Test: Total time: 0:00:34 (0.9494 s / it)\n",
            "Averaged stats: model_time: 0.8041 (0.8139)  evaluator_time: 0.0112 (0.0155)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.16s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.702\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.483\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "BEST VALIDATION mAP: 0.4252524347043286\n",
            "\n",
            "SAVING BEST MODEL FOR EPOCH: 2\n",
            "\n",
            "Epoch: [2]  [  0/404]  eta: 0:27:11  lr: 0.001000  loss: 0.0788 (0.0788)  loss_classifier: 0.0399 (0.0399)  loss_box_reg: 0.0349 (0.0349)  loss_objectness: 0.0030 (0.0030)  loss_rpn_box_reg: 0.0010 (0.0010)  time: 4.0393  data: 1.8984  max mem: 7544\n",
            "Epoch: [2]  [100/404]  eta: 0:09:34  lr: 0.001000  loss: 0.0909 (0.0895)  loss_classifier: 0.0389 (0.0414)  loss_box_reg: 0.0460 (0.0448)  loss_objectness: 0.0012 (0.0019)  loss_rpn_box_reg: 0.0013 (0.0014)  time: 1.8590  data: 0.0529  max mem: 7544\n",
            "Epoch: [2]  [200/404]  eta: 0:06:22  lr: 0.001000  loss: 0.0903 (0.0907)  loss_classifier: 0.0387 (0.0412)  loss_box_reg: 0.0465 (0.0463)  loss_objectness: 0.0007 (0.0018)  loss_rpn_box_reg: 0.0014 (0.0014)  time: 1.8693  data: 0.0550  max mem: 7544\n",
            "Epoch: [2]  [300/404]  eta: 0:03:14  lr: 0.001000  loss: 0.0873 (0.0905)  loss_classifier: 0.0380 (0.0408)  loss_box_reg: 0.0484 (0.0464)  loss_objectness: 0.0017 (0.0018)  loss_rpn_box_reg: 0.0014 (0.0014)  time: 1.8675  data: 0.0457  max mem: 7544\n",
            "Epoch: [2]  [400/404]  eta: 0:00:07  lr: 0.001000  loss: 0.0789 (0.0882)  loss_classifier: 0.0306 (0.0397)  loss_box_reg: 0.0421 (0.0452)  loss_objectness: 0.0011 (0.0019)  loss_rpn_box_reg: 0.0011 (0.0014)  time: 1.8612  data: 0.0514  max mem: 7544\n",
            "Epoch: [2]  [403/404]  eta: 0:00:01  lr: 0.001000  loss: 0.0789 (0.0881)  loss_classifier: 0.0306 (0.0396)  loss_box_reg: 0.0421 (0.0452)  loss_objectness: 0.0012 (0.0019)  loss_rpn_box_reg: 0.0011 (0.0014)  time: 1.8066  data: 0.0477  max mem: 7544\n",
            "Epoch: [2] Total time: 0:12:34 (1.8672 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/36]  eta: 0:01:23  model_time: 0.8491 (0.8491)  evaluator_time: 0.0136 (0.0136)  time: 2.3206  data: 1.1642  max mem: 7544\n",
            "Test:  [35/36]  eta: 0:00:00  model_time: 0.8154 (0.8180)  evaluator_time: 0.0115 (0.0144)  time: 0.9137  data: 0.0454  max mem: 7544\n",
            "Test: Total time: 0:00:34 (0.9617 s / it)\n",
            "Averaged stats: model_time: 0.8154 (0.8180)  evaluator_time: 0.0115 (0.0144)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.793\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.640\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.629\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.684\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "SAVING PLOTS COMPLETE...\n",
            "\n",
            "BEST VALIDATION mAP: 0.5226971427275836\n",
            "\n",
            "SAVING BEST MODEL FOR EPOCH: 3\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss_box_reg █▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_cls █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss_epoch █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_loss_iter █▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_obj █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_rpn █▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val_map_05 ▁▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_map_05_95 ▁▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss_box_reg 0.04519\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_cls 0.03961\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss_epoch 0.08813\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train_loss_iter 0.02393\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_obj 0.00193\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss_rpn 0.00141\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val_map_05 0.7926\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_map_05_95 0.5227\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mteste\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/165grinch/fastercnn-pytorch-training-pipeline/runs/ffdtxeyx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/165grinch/fastercnn-pytorch-training-pipeline\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 3 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240517_202756-ffdtxeyx/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --model fasterrcnn_mobilenetv3_large_fpn --input /content/fastercnn-pytorch-training-pipeline/data/Rock-Paper-Scissors-SXSW-14/test/jpg/10e0gvm_jpg.rf.3b68a834fab647f30a57fc3ea92d4cd2.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YenChJdSY_U7",
        "outputId": "d89d4b03-6ca2-4512-ed85-520d0e1437ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-17 21:10:42.339173: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-17 21:10:42.339229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-17 21:10:42.340686: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-17 21:10:43.424311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n",
            "100% 74.2M/74.2M [00:00<00:00, 173MB/s]\n",
            "Test instances: 1\n",
            "Image 1 done...\n",
            "--------------------------------------------------\n",
            "TEST PREDICTIONS COMPLETE\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fastercnn-pytorch-training-pipeline/inference.py\", line 253, in <module>\n",
            "    main(args)\n",
            "  File \"/content/fastercnn-pytorch-training-pipeline/inference.py\", line 246, in main\n",
            "    cv2.destroyAllWindows()\n",
            "cv2.error: OpenCV(4.8.0) /io/opencv/modules/highgui/src/window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n"
          ]
        }
      ]
    }
  ]
}